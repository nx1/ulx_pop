{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_systems_dataframe(ulx_only=False, beamed=False, half_opening_l_45=False):\n",
    "    systems_df_path = Path('../data/processed/all_systems_df.csv')\n",
    "    df = pd.read_csv(systems_df_path)\n",
    "    if ulx_only:\n",
    "        df = df[df['Lx'] > 1E39]\n",
    "    if beamed:\n",
    "        df = df[df['b'] < 1]\n",
    "    if half_opening_l_45:\n",
    "        df = df[df['theta_half_deg'] < 45]\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['index', 'Unnamed: 0'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_df = load_systems_dataframe(True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I only ran these simulations to 0.4 BH_NS ratio before realising my method could be faster.\n",
    "df_a = pd.read_csv('../data/processed/df_a_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BH_NS_RATIO = 0.1\n",
    "plt.xlabel('alive/dead ratio')\n",
    "plt.ylabel('Number of systems')\n",
    "plt.title('Transient ULX distribution')\n",
    "\n",
    "for BH_NS_RATIO in df_a['BH_NS'].unique():\n",
    "    df = df_a[(df_a['BH_NS'] == BH_NS_RATIO) & (df_a['ratio']!=0) & (df_a['ratio']!=1)]\n",
    "    # df = df_a[(df_a['BH_NS'] == BH_NS_RATIO)]\n",
    "    number_of_systems = len(df)\n",
    "    plt.hist(df['ratio'], bins=50, label=round(BH_NS_RATIO, 2), density=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = list(systems_df.is_bh)\n",
    "Z_list = list(systems_df.Z)\n",
    "\n",
    "is_bh = [my_list[s] for s in df['system_num']]\n",
    "Z = [Z_list[s] for s in df['system_num']]\n",
    "df['is_bh'] = is_bh\n",
    "df['Z'] = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I've realised that some of the systems have far less simulations on them than others, this needs to be sorted\n",
    "print(df['system_num'].value_counts().sort_index())\n",
    "print('==========')\n",
    "print(df['system_num'].value_counts().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_bh'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of poorly sampled system\n",
    "df[df['system_num'] == 529].hist('inclination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inclinations = np.arange(91)\n",
    "dincls = np.arange(1,46)\n",
    "number_of_ulxs = 151\n",
    "\n",
    "repeats = 10\n",
    "\n",
    "number_of_required_simulations = len(inclinations)*len(dincls)*repeats*number_of_ulxs\n",
    "\n",
    "time_per_simulation = 0.3\n",
    "simulation_hours = number_of_required_simulations*time_per_simulation/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['system_num', 'Z', 'is_bh', 'dincl', 'inclination', 'alive', 'dead', 'ratio']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df[df['Z'] == 0.0002]\n",
    "plt.hist2d(df_sub['dincl'], df_sub['ratio'], bins=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_df['P_wind_years'] = systems_df['P_wind']/60/60/24/365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking new lightcurve simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob('../src/new_curve_results/*.csv')\n",
    "res = {}\n",
    "for file in csv_files:\n",
    "    res[file] = pd.read_csv(file)\n",
    "df_new = pd.concat(res.values())\n",
    "df_new = df_new.drop(['Unnamed: 0'], axis=1)\n",
    "df_new['ratio'] = np.divide(df['alive'], (df['alive']+df['dead']))\n",
    "df_new.loc[np.isnan(df_new['ratio']),'ratio']=0\n",
    "df_new_transient = df_new[(df_new['ratio'] != 0) & (df_new['ratio'] != 1)]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_transient.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_new[df_new.duplicated(subset=None, keep='first')]\n",
    "df_new_transient = df_unique[(df_unique['ratio'] != 0) & (df_unique['ratio'] != 1)]\n",
    "df_new['ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_new_transient['dincl'], df_new_transient['ratio'], bins=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df736 = df_new[df_new['system_id'] == 736]\n",
    "df736 = df_new[df_new['inclination'] == 0]\n",
    "df736 = df736.sort_values(by=['theta', 'inclination', 'dincl'])\n",
    "df736 = df736[df736['theta'] == df736['theta'].unique()[0]]\n",
    "df736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['system_id'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_transient['ratio'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sysid in df_new['system_id'].unique():\n",
    "    subset = df_new[df_new['system_id'] == sysid]\n",
    "    subset['inclination'].hist(bins=91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(df_new['inclination'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(df_new['theta'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['system_id'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_transient['ratio'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_new['dincl'], df_new['ratio'], bins=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df_new_transient[df_new_transient['system_id']==883].sort_values(by=['inclination', 'dincl'])\n",
    "plt.hist2d(subset['dincl'], subset['ratio'], bins=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many ULXs will eROSITA see?\n",
    "\n",
    "A first calculation we may perform is what percentage of our ULX population we will be able to see purely due to beaming.\n",
    "\n",
    "the beaming factor, b, for random inclination essentially provides the probability of observing the source down the cone, since it is a ratio of the solid angle of a sphere to the size subtended by the two cones.\n",
    "\n",
    "We may hence obtain a very crude upper limit for the number of ULXs observed by eRosita in the following manner:\n",
    "\n",
    "For our sample of binary systems, we can calculate what percentage of them are ULXs, and what percentage of them are above the eROSITA detection threshold.\n",
    "\n",
    "If we know how many binary systems eROSITA is predicted to observe, we can find what percentage of them would be ULXs from greg's population synthesis, \n",
    "\n",
    "number_of_ulxs/number_of_systems_above_erosita_threshold = number_of_observed_ulxs/number_of_observed_binary_systems\n",
    "\n",
    "https://www.eso.org/sci/meetings/2012/surveys2012/Presentations/Day4-Thursday/Merloni.pdf slide 18 has the eROSITA limits as a function of each observing cycle in units erg/s/cm^2\n",
    "\n",
    "https://www.aanda.org/articles/aa/pdf/2014/07/aa23766-14.pdf performed simulations on the number of XRBs that would be detected by eROSITA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ULXs only\n",
    "all_systems_df = load_systems_dataframe(False, False, False)\n",
    "systems_df = load_systems_dataframe(True, False, False)\n",
    "print(f'number of binary systems: {len(all_systems_df)}')\n",
    "print(f'number of ULXs: {len(systems_df)} ({round(len(systems_df)/len(all_systems_df)*100, 3)}% of all systems)')\n",
    "b_sum = systems_df['b'].sum()\n",
    "print(f'number of visible ULXs: {round(b_sum,0)} ({round(b_sum/len(systems_df)*100,2)}% of all ULXs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EROSITA_stats\n",
    "erosita = pd.DataFrame()\n",
    "erosita['cycle_number'] = [1,2,3,4,8]\n",
    "erosita['f_lim'] = [4.5E-14, 2.8E-14, 2.1E-14, 1.8E-14, 1.1E-14] #0.5 - 2Kev erg/cm^2/s\n",
    "erosita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_df.iloc[988]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earnshaw ULX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulx_file = '../data/external/Earnshaw_ULX_cat/earnshaw_Xraycatalogue.fits'\n",
    "with fits.open(ulx_file) as hdul:\n",
    "    #hdul.info()\n",
    "    data = pd.DataFrame(hdul[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sources with more than 1 obervation\n",
    "sources = data['SRCID'].value_counts()[data['SRCID'].value_counts() > 1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src901 = data[data['SRCID'] == 901].sort_values(by=['MJD_START'])\n",
    "src901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ULX(subset):\n",
    "    if max(subset['EP_8_LUMINOSITY']) > 1E39 and min(subset['EP_8_LUMINOSITY']) < 1E39:\n",
    "        \n",
    "        return \n",
    "\n",
    "def is_always_off(subset):\n",
    "    return max(subset['EP_8_LUMINOSITY']) < 1E39\n",
    "\n",
    "def is_always_on(subset):\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_transients = 0\n",
    "number_of_dead = 0\n",
    "number_of_alive = 0\n",
    "\n",
    "for source in sources.index:\n",
    "    subset = data[data['SRCID'] == source].sort_values(by=['MJD_START'])\n",
    "    if max(subset['EP_8_LUMINOSITY']) > 1E39 and min(subset['EP_8_LUMINOSITY']) < 1E39: #TRANSIENT\n",
    "        plt.figure(figsize=(15,3))\n",
    "        plt.ylabel('Lx')\n",
    "        plt.xlabel('MJD')\n",
    "        plt.title(subset['IAUNAME'].unique()[0] + ' TRANSIENT')\n",
    "        plt.errorbar(subset['MJD_START'], subset['EP_8_LUMINOSITY'], yerr=subset['EP_8_LUMINOSITY_ERR'], fmt='none', capsize=1.5)\n",
    "        plt.axhline(1E39, c='red')\n",
    "        number_of_transients+=1\n",
    "    elif max(subset['EP_8_LUMINOSITY']) < 1E39: #DEAD\n",
    "        number_of_dead+=1\n",
    "    elif min(subset['EP_8_LUMINOSITY']) > 1E39: #Alive\n",
    "        number_of_alive+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Objects in Earnshaw cat: {len(data)}')\n",
    "print(f'Objects with more than 1 observation: {len(sources)}')\n",
    "print(f'Number of Transient ULXs: {number_of_transients}')\n",
    "print(f'Number of alive ULXs: {number_of_alive}')\n",
    "print(f'Number of dead ULXs: {number_of_dead}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie([number_of_alive, number_of_dead, number_of_transients], labels=['alive', 'dead', 'transient'], autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie([number_of_alive, number_of_transients], labels=['alive', 'transient'], autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
