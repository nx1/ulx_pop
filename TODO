DONE
====
[x] Recreate all systems dataframe with eta = 0.2
[x] Install xspec
[x] install ulxlc 
[x] Re-run MC lightcurves
[x] Create N_lim dict for 0 inclination curves
[x] Write fast lighturve processor
[x] Process MC lightcurves
[x] Recalculate BH/NS ratio plots (change Z order)
[x] Change x-label on BH/NS to actual percentages 
[x] Check the transient classification to explain weird things like the 0.8 thing.
[x] eRASS simulation with BH/NS ratio
[x] eRASS simulation with dincl cut
[x] Change ULXLC output to linear spacing
[x] Change r_isco = r_in = 1.25 for BHs (Except in equation for zeta where r_in = 6 R_g)
[x] Re-do eRASS deterministically
[x] Omit free body precession
[x] Message Greg wrt getting orbital period for our sample
[x] re-derive the form for zeta
[x] Change lightcurve dincl and i plots to percent
[x] Combine lightcurve and dincl plot into 1 figure.
[x] Obtain figures for the orbital period from Universe @ Home https://universeathome.pl/universe/bhdb.php
[x] Download the new greg data
[x] add additional columns to new data 
[x] Run new data through lightcurve classifier
[x] Calculate precessional period from Phil Charles relation
[x] Put precessional period into eRASS sims
[x] Use Phil Charles relation for a second form of precession comparison
[x] Check lower limit of zeta = 2
    - See Latex notes wiktorowicz 2017
[x] Get ULXLC working outside of XSPEC
[x] Add analysis directly in C for speed
[x] Mention what we do with the ISCO
[x] Why 12 years cut for prcession period?
    get rid of precessional angle cut
[x] Check to see if our XLF matches greg's one
    - Greg did not show a XLF however the most highly beamed sources at 10^41 are BH which is the same as greg.
[x] Is this (SS433) half angle or full angle? (is half)
[x] Ask Matt about LMXRB classification
[x] Seperate out NS and BH in MC in XLF
[x] Mention eRASS sensitivity and how it is a flux limited survey
[x] Check ULX system weighting

====
TODO
====

Code
----

Plots
-----
[ ] XLF - The low luminosity ULXs dominate the entire population \citep{Earnshaw_ULX_cat} and these are thought to be dominated by black hole systems. - is this now true?}
[ ] XLF - Show the distributions before precession / after precession etc.
[ ] XLF - is the tail of dominated by black holes?
[ ] XLF - show a function of erass cycle above.
[ ] XLF - Include duty cycle 
[ ] ADT - Duty Cycle Effect
[ ] eRASS - Duty Cycle Effect

Paper
-----
[ ] somewhere we need to note that we assume only the beamed emission is detected not the emission from the spherisaton radius or photosphere
[ ] What do we do about the DIM systems?
[ ] Expand what you mean about combination (of metallicities)
[ ] Is the underlying population still 500?
[ ] How many persistent sources in there?
[ ] What properties did the sample have (for table)
[ ] Define what you mean by sub-sample
[ ] For what BH ratio and size of underlying population?






#####################################################################################
NOTES
=====

eRASS simulation
----------------
    [x] 1.  Take total population of 955 ULXs, mix of BHs/NSs
    [x] 2.  create fake parent population of 500 ULXs of given BH/NS ratio
  **[ ] 3.  For each system, determine weather it is persisent_alive, persisient_dead or transient.
    [ ] 4.  Check curve_classifications


            - If the system was not sampled, then P_wind > 4 years and the system is treated as persistent
                - retrieve the probability of the source being alive on the first eRASS observation via
                  sampling the first cycle of its lightcurve              
                - We will for now make the assumption that this probability is 0.5 for these systems.
                  (50/50 alive or dead)


            - If the system sampled does have eRASS transient probabilities, retrieve them
              and determine which cycle the source was observed as transient in.

            - Also determine the probability of alive on first cycle. For now we will use 0.5
              This will tell us if the source was classified as alive or dead up until the eRASS
              cycle it was determined to be transient in.

    [ ] 5.  Gives us alive vs transient (as function of total population demographic)
    [ ] 6.  Repeat for new realisations up to ~1000
    [ ] 7.  Repeat for dinc cut
    [ ] 8.  Repeat 1-7 for new BH/NS ratio



*Omitting Free-body precession:
	[ ] Find formula for the free-free body precession
	[ ] compare if it is lense-thirring or free-free
    - https://arxiv.org/pdf/1307.6026.pdf
    - Also look at papers for Herr - X1
    - Consider using Phil Charles model for an extra form of comparison.


**old chain:
P(ulx_realisation_being_transient vs erass cycle) ended up being miscalculated (error in sampling code)
            - We have P(alive), P(dead) and P(transient) for all ULX systems
                - Those with P(alive) = 1.0 are unbeamed (theta/2 > 1) ULX systems.
                - probability of transient systems  (theta/2 < 45 )may be obtained by:
                  Number of realisations in each classification / Total number of realisations. (subject to dincl cut)

            - We can either use these probability values or simply draw a realisation
              which would recreate the same probabilities.
 


How to store a database in code?
--------------------------------
tables.py
tables.curve_classifications()
lookup.N_lim_dict()




erass sim output:
-----------------
eRASS cycle         = [1  ,   2,   3,   4, ...,   8]
alive_persistent    = [100, 100, 100, 100, ..., ...] = 100
dead_persistent     = [50 , 50 , 50 , 50 , ..., ...] = 50

number_of_alive     = [300, 275, ]
number_of_transient = [0  , 150, ]			<-- not used
number_of_dead      = [100, 75 , 75, 75, 75]            <-- not used

include the additional ones that are unbeamed and therefore always alive.


Changing the accretion efficiency has actually resulted in my populations
for ULX, beamed ULX etc Changing, therefore old ids are no longer valid and
I have chosen to change them to the absolute ids assigned at the start if something
like this were to happen again.

I have also thought that the previous quantity that we were calculation
known as 'ratio', i.e. The measure of how transient a paticular system is
actually not paticularly of use.
    1. Previously calculating this value basically showed that the distribution of transient systems
    just seemed to be 'guassian' on ratio=0.5, i.e the majority of transient systems were on 50% of the time.
    So far the quantity is useful for creating a pretty plot showing the effect of dincl on the transient population
    however the same effect is much better illustrated by showing the relative number of alive/dead/transient systems
    against dincl.

What i want to save from the lightcurves?
1. classification | alive/dead/transient
2. Simulation information
    The changing quantities for ULXLC are:
        theta - dincl - inclination

Since a lot of the curves will likely have the same theta, (maximally beamed saturation)
I can probably avoid a lot of repeated calculations for these systems.


1. The MC alive/dead/plot and simulations are only run on:
    ULX systems \w \theta / 2 < 45.
    I need to make this clearer in the paper.

2. What percentage of the TOTAL ULX population is either Alive/Dead/Transient as a function of dincl?

    141 are potentially alive/dead/transient for which we calculate MC distributions.
    the remaining are always alive.


================

# Alive/Dead/Transient Classification
There are 123 ULX systems with beaming < 1 and opening angles less than 45

of these 123 systems, there are only 87 unique different opening angles.

We only need to simulate curves for unique dincl, theta, and inclination

There are 87 * 46 = 4002 0 Inclination curves corresponding to a unique opening angle and precessional angle

while there are 87 * 46 * 90 = 380,180 curves corresponding to arbirary inclination

In total there are thus 380,180 + 4002 = 87*46*91 = 384,182 different curves.

We wish to calculate for every SYSTEM what it's alive/dead/transient classification looks like

thus we will have 123*46*91 = 514,878 unique results (4,186 per system)

For a given system we would like:

    minimal:
    parent_system_id, Lx, lc_min, lc_max, N_lim, theta, dincl, inclination, classification


1. get min and max of curve
2. Calculate the ULX limiting level for a specific system_id + theta + dincl combination
3. 


Matt Emails 24-25/04/2019
-------------------------
1. I'm confused - did you not change r_in in the precession equation for spin?
I'm still using r_in = r_isco = 6 R_g for both NS & BHs
I was previously using r_in = 1.25 for NS. Did you want me to use something else?



2. In addition to the previous email, I'm not clear on how you're extracting the underlying population BH% from eRASS -
I get the sense you're working out how many BHs vs NSs are in the *transient* population rather than the underlying population (i.e. by improving the constraints in Fig 4)
- is that right?

So from the lightcurves we created, I'm sampling from all the curves that were classified as transient (circled in red) with the additional cut of considering systems with P_wind < 4 years.
with the additional cut of P_wind, the number of unique lightcurves drops from 238956 to 110457 (123 Parent ULXs to 54).

I'm then sampling from the 110457 lightcurves with a specified %_BH and for each lightcurve, I obtain the probability at each eRASS cycle through sampling the curve 10,000 times.



3. Last email from me tonight. If I'm correct, the LT period formula only comes into play with eRASS correct?
If so then we can claim our results preceding that are essentially independent of the mechanism driving it.
This isn't the case for eRASS which as I mentioned in my previous emails we need to look at.

Correct, the spin, radii calculations and LT formulas are only used for the eRASS estimate.



4. It occurs to me that the biggest question-mark is the effect of delta (i).
We don't have any priors for this so we should investigate the effect (and how robust our inferences are) by limiting it to smaller values, e.g. SS433's delta i is 20 degs.

I also had the same thought, we could potentially do each step of the analysis while also considering precessional ranges eg 0 - 10, 0 - 20 etc...



5. I had some time last night to think about how to make the eRASS section more constraining and I think we can do the following.

The *number* of transients (not proportion of a population but the actual number) will depend on the total population (hidden as well as visible) and proportion of NS/BH in the parent (Figure 4),
and the delta(i) of the precession.

You can picture this by having the number of transients detected (cumulative or otherwise) plotted versus time (or eRASS cycles).
If the proportion of NSs in the parent is large then there will be a large number of transients so the final value on the y axis will be large.
Conversely if the proportion is small then the final value on the y axis will be small.
Then the different delta(i) just tells you how quickly (the rate of change of transient detection) this peak value is reached.
If correct, then eRASS could in principle indicate both by reproducing observational equivalents.


are you saying we could look at the relative change in the population number of transients or transient+alive or transient+alive+dead after each cycle and actually compare that to
what we find?



Matt Meeting 27/04/2020
Change r_isco=r_in=1.25 for BHs
Try earlier plots for dincl < 20 deg
Bimodal flux distribution could can be achieved using ULXLC ==  maybe not propeller?


29/04/2020
----------

Went on a bit of a mad one and decided to completely revamp the code.

Instead of storing all the systems in one big pandas dataframe, we now have a new data structure called a System.

This data structure represents one ulx to come out of Greg's startrack simulation.

Many Systems compose a Population, the new datastructure that has replaced the large dataframe that was previously in use.
It is still possible to export any system to a dataframe using a function, this ensures that old notebooks and exploratory analysis can still take place, however it is definitely
more robust.


One system may have many curves, corresponding to paticular realisations of the system in question, eg for a given dincl and inclination.

We need a way to connect curves and systems.

System.get_curves()
Curve.parent_system

Something that has plagued this entire process throughout everything is that I do not have a way of keeping track of the curves in a good way.

I have previously been using naming conventions on the curves in order to try and keep track of things.
But this has not been consistent

I was previously using something like
id-angle-dincl
then I changed it to
angle-dincl-i

Whatever I chose to do it needs to be consistent and fixed, let's say in future I wanted to change beta or something
now all my old curves have the old beta and the new ones have the new beta and I have no way of keeping track which ones are which.

Each curve has far to many varibles to be stored in a filename therefore I think going back to the old way of having a uuid for each curve
with a lookup table may prove to actually be the most robust thing, however It needs to be implemented properly or it's gonna be a messs.


ulxlc_grid = 



30/04/2020
----------
Less transient systems in total.
Less transients across all %bh and more alive.
This brings up the %bh estimate.

Vasiloplolis paper on freee body precession.


15/05/2020
----------
Been picking away at this eRASS simulation for a few weeks, I'm getting a little frustrated that things have been so slow.
However there has been some measureable progress I think.

I've written an eRASS routine that does the following.

1. Draw 500 ULXs from the parent population
2. Specify a paticular realisation for each ULX. (dincl + inclination)
3. Runs through each of the 500 systems and classifies them as:
    - Persistently alive
    - Persistently dead
    - Transient
4. If they are transient, we fetch the erass simulation and for each system we check how
the observations of the source change over each erass cycle.
That is to say, was it originally observed as a ulx or not, and in which cycle (if any) did it
cross the 1e39 threshold and thus become a transient system.

We repeat this process for 100x for different draws of 500 ULXs.
and we changed the bh_percentage of the parent population, as well as the
precessional angle cuts (dincl) to see how things varied.

The code is ugly and could probably do with being rewritten but hey that's life. :^)




==============================
Matt Meeting 26/5/20
--------------------
1. Attend Belloni meeting
2. Matt moved some stuff about in the paper.
3. Make sure you can rederive things eg eq (6) (Zeta)
4. Make sure you're confident on the things you're writing are correct

5. The lower limit we put of Zeta = 2 may need some looking at
it's a bit position of the outer photospheric readius.

B = 10^13 is a magnetar.

6. If we put in the free-free precession, we don't have any a-priori knowledge of the field strength or spin period.
We don't understand how the field strength and how it evolves, as a consequence of supernovae fallback, or consequence of accretion rate
or even as a consequence of the time it takes for the orbit to shrink where it can begin accreting. The field strength tells you about the spin period.

If it's an age thing, the lower the magnetic field the older the system, so it will spin down. The torque depends on the radius, which depends on the field strength
which depends on the radius.

7. We take out Free-Free precession, and instead use the empirical precession by Townsend and Charles.

Taking that we still need to caveat it in the discussion
8. It's still unclear what the origin of precession is:
    If it's lense thirring then blah
    If it's this other thing that scales slightly differently, then we have some lose empircal constraints
    BUT there are probably several mechanisms operating which may make things slightly tougher
    We will explore this in future.

9. Matt was looking at something called Ohmic diffusion which tells us how the field decays for NS.
The results are cyclical outbursts from NS.

Do LT - Do Empircal thing --> Bung it to co-authors.

10. Drop Thomas an email, and ask if he can send me the periods or binary seperations so i can put in the period.

11. If we can exlude parameter space for dincl/bh erass then that's good.

12. Our results should relate back to the plot I made with Hannah catalgue limits on it.

13. In Greg's 2017 Paper he mentions creating 10^7 binary systems then scaling them to the MWEG.
I've dug up an old email and this is what he says:

=================================================================
On Fri, 26 Jul 2019 at 22:06, Khan N. <nk7g14@soton.ac.uk> wrote:
Dear Greg,
Hope things are going well.
I was writing just to ask for some clarification on a particular point in your 2017 paper: The Origin of the Ultraluminous X-ray Sources.
When you say that you simulated the evolution of 2×107 binary systems for every model and scaled the results to the Milky-Way equivalent galaxy, what exactly does this scaling involve? I attempted to look (Lic-quia & Newman 2015) and wasn't able to find anything specific.
Kind regards,
Norman


Dear Norman,

The thing is quite simple, although I agree that it is not well explained in the paper.

First of all, the Licquia & Newman 2015 reference is just to the MW mass. The scaling is strictly technical thing. We simulate N binaries from a limited initial parameter space. Then we calculate the total simulated stellar mass (M_sim) of all stellar systems (sinble and binaries) from the entire initial parameter space, which include these N binaries. The scaling factor to the MW galaxy is then simply SF=M_MW/M_sim.

I hope it is clear. If not, please let me know.

Cheers,
Greg
==================================================================



================
29/05/2020

Emailed Greg, he tells me:

 
Q. Is the combination of the two identifiers completely unique for a binary system?

A. Yes, for any model idum+iidd identify exactly one binary.
Please note that  idum+iidd (binary) in one model is in general different to
the same idum+iidd values in other models.
 
 
Q. Would I be able to run through all the *_binary.dat.tbz files to obtain the semi-major axis (a) for each system?

A. In general yes, but choose only models which interest you (probably std, lowZ and midZ). Then you can pick interesting systems (ULXs?) and keep only them on your disk.
 


=======================
01/06/2020 June life


- Belloni Lecture | Part - 2
---------------------------------

Flux is subject to poisson noise.

If you expect \lambda counts then:

    P(k) = \frac{\lambda}^{k}}{k!} e^{-\lambda}



- This is the same as saying that photon's arrival time is independent.
- Exponential waiting time between photons

Uncorrelated noise - White noise - Flat spectrum
    With this noise --> Chi^2 with two DoF

    P = \frac{2} {N_{phot}} |a|^{2}     (Leahy Normalisation)
    P_{total} = P_{signal} + P_{noise}
    Noise and signal independent (in practice this is not true)

    Logarithmic binning of power spectrum

    \Delta \nu = \Delta \nu_{j-1} * (1+f)

==================================
2/6/2020

Meeting with Matt,

So we're trying to get out the orbital periods for our sample.

We don't want to re-run literally everything from scratch, and so Matt suggested the following idea:

maybe we could use the new catalogue to find out the distribution of orbital periods as a function of m, Z, mdot etc and simply draw from that.

We're going to talk about the AGN paper on thursday too, 

We need to build a posterior probability distributioni


maybe a corrlation between m/mdot -James


==============
3/6/20

I've made an attempt to try and estimate the orbital period from the known startrack database.

Kepler's third law states that the orbital period T of two point masses
orbiting each other in a circular or elliptical orbit is given by:
    
    T = 2 \pi \sqrt{\frac{a^3}{GM} }
    
    Where M is the mass of the more massive body

What I have:
	Z
	tage
	Ma	(mass of CO)
	mdot

What is in the databse:
	Ma
	Mb


Alive_persistent + Alive + Transient / Total = number of observable ulxs
Alive+ transient - dead  + max inclination min inclination ---> uniform inclaintions may hide upto 20% of ulx from view

How does max(Lx) vary with dincl and inclination (probably in dauser already)

10/6/2020
---------
Paper review:
What is on tap? The role of spin in compact objects and relativistic jets.
- Ashley L. King

Abstract:
Looked at a bunch of sources,
modelled with Guassian line features
Modeled others with Relativistic blurred disk reflection model that measure spin
====================
12/6/20


Our paper is trying to answer:

What is the effect of precession on the observed population of ULXs?

The larger the precessional angle, the greater number of transient ULX are observed
Likewise an increase in the relative number of neutron stars also increases the number of transient systems observed.

Discussion:

Our question for this paper was to answer the question of what is the effect of precession in its various forms
on the observed population of ULXs. The conical emmission geometry created through means of supercritical accretion
if subject to precession may affect the observational demographic of the ULX population. 


At low metallicities Z=0.0002 (1\% Z_{\sol}) our sample of ULXs is predominantly dominated by BH,
at mid metallicities Z=0.002  (10\% Z_{\sol} our sample of ULXs is also predominantly dominated by BH,
at std metallicities Z=0.02   ($Z_{\sol}$ we find few ULXs

For  our ULX samplew was composed of 

If our ULX sample is representative we find that approximately \sim 13 \% of ULXs display beaming while the remaining 73\% are always visible

Approximately (\sim 13 \%) of our population displayed beaming for which we assumed that precession was present.

By performing simulations on the 123 (12\%) of our ULXs that displayed strong levels of beaming


===========
23/07/2020
----------
Matt has been away for this week living it up in some fancy house in Essex.

I've been left to my own devices to attempt to use Greg's new data to reproduce the results.

I have spent the last two days bungling through the ULXLC code and have managed to figure out how to create lightcurves in C naitvely. (Thanks to David Williamson)

The next step is to reproduce the results using this new dataset.

timing: ulxlc_model()

iterations:     Time Taken:
100             0.04 sec
1000            0.4  sec
10000           4.1  sec
100000          41   sec



0. startrack data
Raw datafiles from STARTRACK located in /data/external/data_mdot
The data from these files were combined into the file /data/processed/startrack_concat.csv
From this point forward, the unique system_id of each system is specified by the index in startrack_concat.csv

1. src/data/process_startrack.py
Takes the data from /data/processed/startrack_concat.csv
and calculates various other quantities which are saved in the file
/data/processed/all_systems_df.csv


2. src/ulxlc_runner.py
will sample systems from a df_a.csv (selecting only the systems that are beamed ULXs with opening angles < 45)
and run ulxlc to create a lightcurve with the system's specific parameters and the specified parameters for ULXLC.
The lightcurves are saved with the pattern:

theta-dincl-inclination.txt

Where theta and dincl are the half opening angles and the precessional angles.

and all lightcurve files are saved in data/curves/

For our simulations, the following fixed parameters were used:
period  = 10.0
phase   = 0.0
beta    = 0.2
norm    = 1.0
dopulse = 0.0


3. src/create_normalisation_lookup.py
Run through 0 inclination lightcurves and calculate normalisation ULX
limits at 1E39 ergs equivilent, store the output in a .pkl file for further use.

The pickle file can be found in /data/processed/N_lim_dict.pickle

final dict is in the form:
N_lim_dict = {system_id-dincl-inclination : N_lim}


3. src/curve_classifier.py
Used to process the lightcurve files and classify the system as either alive/dead/transient.
Does this in a 'quick' manner i.e does the lightcurve span over the 1e39 range and therefore is transient.

The results of this processed are saved in the file:
/data/processed/curve_classications.csv


4. src/df_a_analysis.py
4. src/bh_vs_classification.py

simulates the effect of sampling systems from the FULL ulx population
in a specified BH ratio and the the number of alive/dead transient systems


1. sample a N ULXs in a specified bh ratio.
2. Is it visible
seperate by metallicity and tage.


Could we calculate for each system, a probably distribution for
its curve classification?

yes, by sampling from them we are essentially doing that.





samples from curve_classifcations to calculate the effect of the
BH_ratio on the alive/dead/transient population


The results from these simulations are saved in:
data/interim/sims_with_metallicity/{Z}/{results.csv}


5. alive_dead_transient_plotter.py
Is used to plot the results from step 4.

ULX System
-----------
- Z (Metallicity)
- tage (Age)
- mass
- mdot
- is_bh
- L_Edd     (Eddington Luminosity)
- eta       (Accretion Efficiency)
- mdot_Edd  (mdot in Eddington units)
- mdot
- Lx_iso
- b
- Lx
- theta_half_deg (opening angle, theta/2)
- inclination
- dincl
- zeta      (cotangent of the wind opening angle)
- spin
- R_g
- r_schw
- r_isco
- r_in
- r_sph
- r_out
- P_inflow_at_r_sph
- P_envolope
- P_wind
- P_Free_precession

Population
----------
- size
- N_bh
- N_ns
- bh_percent
- ns_percent
- Z
- tage

Curve (LightCurve)
------------------
- path
- filename

- period
- phase
- theta
- inclination
- dincl
- beta
- dopulse
- norm




eRASS

prob_eRASS 1 - 8 : 0.00 - 1.00

Sample N systems from whole ULX population.
What percentage of the whole population will be observed after N cycles?

System 1:
    N_samples = 10 000
    sample 1:      Flux         Above?      Transient?
        - Cycle 1: 1E40         True        False           
        - Cycle 2: 2.5E39       True        False
        - Cycle 3: 1E38         False       True
    sample 2:   
        - Cycle 1: 1E38         False       False
        - Cycle 2: 2E38         False       False
        - Cycle 3: 1.5E38       False       False
    Sample 3:
        - Cycle 1: 2E39         True        False
        - Cycle 2: 3E39         True        False
        - cYCLE 3: 4E39         True        False


f(above):
    above       = [1,1,1,1,1,1,1,1]
    transient   = [0,0,0,0,0,0,0,0]

    above       = [0,0,0,0,0,0,0,0]
    transient   = [0,0,0,0,0,0,0,0]

    above       = [0,0,0,1,0,1,0,1]
    transient   = [0,0,0,1,1,1,1,1]

    above       = [1,1,1,0,0,0,0,0]
    transient   = [0,0,0,1,1,1,1,1]


f(above):
    transient = [0] * 7
    last = above[0]

    for i in above[1:]:
        if last != current:
            transient[i:] = 1
            break

    return transient


samples = [[0,0,0,0,0,0,0]
           [0,0,0,0,0,1,1]
           [0,0,1,1,1,1,1]
           ...
           [0,0,0,1,1,1,1]]

probability = N_transient / N (mean)


Curve_classifications
id   curve_id    system_id        Classification    P
0    284         937              Alive             [0] * 7
1    238         102              Transient         []
3    519         857              Dead              [0] * 7



Possible things we could investigate:

Curve_id --> 
    - period
    - phase
    - theta
    - inclination
    - dincl
    - beta
    - dopulse
    - norm

system_id:
    - Z (Metallicity)
    - tage (Age)
    - mass
    - mdot
    - is_bh
    - Lx
    - theta_half_deg (opening angle, theta/2)
    - inclination
    - dincl
    - spin
    - P_wind
    - P_Free_precession



Pick N samples from whole ULX population:

N           = 500
N_alive     = 30
N_Dead      = 70
N_transient = N - N_alive - N_dead - N_transient

%_alive     = N_alive / N
%_dead      = N_dead / N
%_transient = N_transient / N



Transient systems:
sys1: P = [0, 0.35, 0.38, 0.56, 0.88, 1.00]
sys2: P = [0, 0.63, 0.72, 0.98, 1.00, 1.00]
...
sys:  P = [                               ]

mean  P = [0, 0.73, 0.92, 1.00, 2.00, 1.00]
std   P = 


After which cycle was the system observed as transient?
system 1
    - Run 1:    6th
    - Run 2:    5th
    - Run 3:    5th
    Average = 6+5+5 / 3 = 5.333     []
    

Impose cuts for precession angles:
    0 - 10
    0 - 20
    0 - 30
    0 - 40

Count the total unique systems in each cut


==============
Things we can measure with eRASS:
    - cycle number
    
    - number of total ulxs
    - number of new ulxs
    - number of alive ulxs
    - number of transient ulx

- Impose constraints 0 - 10 dincl.
Draw 500 ULXs
    For each ulx
        - Find all sub-systems (dincl + i combinations)
        - number_of_sub_systems (46*91)   = 4186
        - number_of_alive_sub_systems     = 1000    (constant over all erass cycles)
        - number_of_dead_sub_systems      = 1000    (constant over all erass cycles)
        - number_of_transient_sub_systems = 2186

        - For the transient sub systems:
            get their erass transient probabilities
                P1 = [0, 0.25, 0.5, 0.75, 0.8, 0.9, 0.98, 1.00]
                P2 = [0, 0.35, 0.6, 0.65, 0.7, 0.9, 0.94, 0.998]
                ..etc

            calculate the number of transients for each eRASS cycle
                 sum all the probabilites
